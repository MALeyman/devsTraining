{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Автор: Лейман М.А.   \n",
    "Дата создания: 22.03.2025  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классы датасета  \n",
    "'building': 0,      \t\tздание  \n",
    "'cable-tower': 1, \t\tкабельная вышка  \n",
    "'cultivation-mesh-cage': 2,  \tсетка для выращивания  \n",
    "'landslide': 3, \t\tоползень  \n",
    "'pool': 4, \t\t\tбассейн  \n",
    "'prefabricated-house': 5, \tсборный-дом\"  \n",
    "'quarry': 6,\t\t\tкарьер  \n",
    "'ship': 7, \t\t\tкорабль  \n",
    "'vehicle': 8,\t\t\tтранспортное средство  \n",
    "'well': 9\t\t\tколодец  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Названия классов\n",
    "class_names = [\"building\", \"кабельная-вышка\", \"cultivation-mesh-cage\", \"landslide\",\n",
    "               \"pool\", \"prefabricated-house\", \"quarry\", \"ship\", \"vehicle\", \"well\"]\n",
    "\n",
    "\n",
    "class_names2 = [\"здание\", \"кабельная вышка\", \"сетка для выращивания\", \"оползень\",\n",
    "               \"бассейн\", \"сборный-дом\", \"карьер\", \"корабль\", \"транспортное средство\", \"колодец\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразование датасета в формат YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Пути к папкам\n",
    "xml_dir = \"dataset/target\"  # Где лежат XML\n",
    "output_txt_dir = \"dataset/target_yolo\"  # YOLO разметка\n",
    "os.makedirs(output_txt_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def convert_voc_to_yolo(xml_file, output_dir):\n",
    "    \"\"\" \n",
    "        Конвертирует датасет в YOLO формат\n",
    "    \"\"\"\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Получаем размеры изображения\n",
    "    size = root.find(\"size\")\n",
    "    width = int(size.find(\"width\").text)\n",
    "    height = int(size.find(\"height\").text)\n",
    "\n",
    "    yolo_labels = []\n",
    "    for obj in root.findall(\"object\"):\n",
    "        class_name = obj.find(\"name\").text\n",
    "        if class_name not in class_names:\n",
    "            continue\n",
    "        class_id = class_names.index(class_name)\n",
    "\n",
    "        bbox = obj.find(\"bndbox\")\n",
    "        xmin, ymin, xmax, ymax = map(int, [bbox.find(\"xmin\").text, bbox.find(\"ymin\").text,\n",
    "                                           bbox.find(\"xmax\").text, bbox.find(\"ymax\").text])\n",
    "\n",
    "        # Нормализация координат\n",
    "        x_center = (xmin + xmax) / (2 * width)\n",
    "        y_center = (ymin + ymax) / (2 * height)\n",
    "        bbox_width = (xmax - xmin) / width\n",
    "        bbox_height = (ymax - ymin) / height\n",
    "\n",
    "        yolo_labels.append(f\"{class_id} {x_center} {y_center} {bbox_width} {bbox_height}\")\n",
    "\n",
    "    # Записываем в файл\n",
    "    filename = os.path.basename(xml_file).replace(\".xml\", \".txt\")\n",
    "    with open(os.path.join(output_dir, filename), \"w\") as f:\n",
    "        f.write(\"\\n\".join(yolo_labels))\n",
    "\n",
    "\n",
    "\n",
    "# Обработаем датасет\n",
    "\n",
    "# Обрабатываем все XML\n",
    "for xml_file in os.listdir(xml_dir):\n",
    "    if xml_file.endswith(\".xml\"):\n",
    "        convert_voc_to_yolo(os.path.join(xml_dir, xml_file), output_txt_dir)\n",
    "\n",
    "print(\"Конвертация завершена!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение датасета  \n",
    "train  \n",
    "val  \n",
    "test  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def splitting_dataset(image_dir=\"datasets_full/images/train/\", label_dir=\"datasets_full/labels/train\" ):\n",
    "    \"\"\" \n",
    "        Разделяет датасет\n",
    "    \"\"\"\n",
    "\n",
    "    # Пути для разделённых данных\n",
    "    output_dirs = {\n",
    "        \"train\": (\"datasets/images/train\", \"datasets/labels/train\"),\n",
    "        \"val\": (\"datasets/images/val\", \"datasets/labels/val\"),\n",
    "        \"test\": (\"datasets/images/test\", \"datasets/labels/test\"),\n",
    "    }\n",
    "\n",
    "    # Создаем папки, если их нет\n",
    "    for dirs in output_dirs.values():\n",
    "        os.makedirs(dirs[0], exist_ok=True)  # images\n",
    "        os.makedirs(dirs[1], exist_ok=True)  # labels\n",
    "\n",
    "    # Получаем список файлов\n",
    "    image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))])\n",
    "\n",
    "    # Перемешиваем данные\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # Разделение: 70% train, 20% val, 10% test\n",
    "    train_split = int(0.7 * len(image_files))\n",
    "    val_split = int(0.9 * len(image_files))\n",
    "\n",
    "    splits = {\n",
    "        \"train\": image_files[:train_split],\n",
    "        \"val\": image_files[train_split:val_split],\n",
    "        \"test\": image_files[val_split:],\n",
    "    }\n",
    "\n",
    "    # Копируем файлы\n",
    "    for split, files in splits.items():\n",
    "        img_out, lbl_out = output_dirs[split]\n",
    "\n",
    "        for file in files:\n",
    "            shutil.copy(os.path.join(image_dir, file), os.path.join(img_out, file))\n",
    "\n",
    "            # Копируем аннотации (YOLO .txt или XML)\n",
    "            label_file = os.path.splitext(file)[0] + \".txt\"\n",
    "            if os.path.exists(os.path.join(label_dir, label_file)):\n",
    "                shutil.copy(os.path.join(label_dir, label_file), os.path.join(lbl_out, label_file))\n",
    "\n",
    "    print(\"Датасет успешно разделён!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Датасет успешно разделён!\n"
     ]
    }
   ],
   "source": [
    "splitting_dataset(image_dir=\"datasets_full/images/train/\", label_dir=\"datasets_full/labels/train\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аугментация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аугментированный датасет сохранён!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# Пути к датасету\n",
    "input_images_dir = \"datasets/images/train\"\n",
    "input_labels_dir = \"datasets/labels/train\"\n",
    "output_images_dir = \"datasets_augmented/images/train\"\n",
    "output_labels_dir = \"datasets_augmented/labels/train\"\n",
    "\n",
    "# Создаем выходные папки\n",
    "os.makedirs(output_images_dir, exist_ok=True)\n",
    "os.makedirs(output_labels_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def clip_bbox(bboxes):\n",
    "    \"\"\"Ограничивает координаты bbox в диапазоне [0,1]\"\"\"\n",
    "    clipped_bboxes = []\n",
    "    for box in bboxes:\n",
    "        class_id, x, y, w, h = box\n",
    "        x = max(0, min(1, x))\n",
    "        y = max(0, min(1, y))\n",
    "        w = max(0, min(1, w))\n",
    "        h = max(0, min(1, h))\n",
    "        clipped_bboxes.append([class_id, x, y, w, h])\n",
    "    return clipped_bboxes\n",
    "\n",
    "\n",
    "def adjust_brightness(image, factor=1.2):\n",
    "    \"\"\"Изменение яркости изображения\"\"\"\n",
    "    return np.clip(image * factor, 0, 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "def add_noise(image, mean=0, std=25):\n",
    "    \"\"\"Добавление случайного гауссовского шума\"\"\"\n",
    "    noise = np.random.normal(mean, std, image.shape).astype(np.int16)  # int16, чтобы избежать переполнения\n",
    "    noisy_image = np.clip(image.astype(np.int16) + noise, 0, 255)  # Обрезаем в диапазон [0, 255]\n",
    "    return noisy_image.astype(np.uint8)\n",
    "\n",
    "\n",
    "def flip_image(image, bboxes, flip_code):\n",
    "    \"\"\"Отражение изображения и корректировка аннотаций\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    flipped_img = cv2.flip(image, flip_code)\n",
    "    \n",
    "    new_bboxes = []\n",
    "    for box in bboxes:\n",
    "        class_id, x, y, bw, bh = box\n",
    "        if flip_code == 1:  # Горизонтальное отражение\n",
    "            x = 1 - x\n",
    "        elif flip_code == 0:  # Вертикальное отражение\n",
    "            y = 1 - y\n",
    "        new_bboxes.append([class_id, x, y, bw, bh])\n",
    "    \n",
    "    return flipped_img, new_bboxes\n",
    "\n",
    "\n",
    "def rotate_image(image, bboxes, angle=15):\n",
    "    \"\"\"Поворот изображения и корректировка аннотаций\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated_img = cv2.warpAffine(image, matrix, (w, h))\n",
    "    \n",
    "    # Аннотации НЕ меняем (нужно пересчитывать координаты)\n",
    "    return rotated_img, bboxes\n",
    "\n",
    "\n",
    "def scale_image2(image, bboxes, scale_factor):\n",
    "    \"\"\"Масштабирование изображения\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    new_h, new_w = int(h * scale_factor), int(w * scale_factor)\n",
    "    resized_img = cv2.resize(image, (new_w, new_h))\n",
    "\n",
    "    # Корректировка аннотаций (меняем размер bboxes)\n",
    "    new_bboxes = []\n",
    "    for box in bboxes:\n",
    "        class_id, x, y, bw, bh = box\n",
    "        x, y, bw, bh = x * scale_factor, y * scale_factor, bw * scale_factor, bh * scale_factor\n",
    "        new_bboxes.append([class_id, x, y, bw, bh])\n",
    "    \n",
    "    return resized_img, new_bboxes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def scale_image(image, bboxes, scale_factor):\n",
    "    \"\"\"Масштабирование изображения с сохранением YOLO-аннотаций (нормализованных).\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    new_h, new_w = int(h * scale_factor), int(w * scale_factor)\n",
    "\n",
    "    # Масштабируем изображение\n",
    "    resized_img = cv2.resize(image, (new_w, new_h))\n",
    "\n",
    "    if scale_factor > 1:\n",
    "        # Увеличение -> Обрезка центра\n",
    "        crop_x = (new_w - w) // 2\n",
    "        crop_y = (new_h - h) // 2\n",
    "        final_img = resized_img[crop_y:crop_y + h, crop_x:crop_x + w]\n",
    "\n",
    "        # Корректируем YOLO боксы (центр + размер)\n",
    "        new_bboxes = []\n",
    "        for class_id, x, y, bw, bh in bboxes:\n",
    "            x = ((x * new_w) - crop_x) / w\n",
    "            y = ((y * new_h) - crop_y) / h\n",
    "            bw = (bw * new_w) / w\n",
    "            bh = (bh * new_h) / h\n",
    "            new_bboxes.append([class_id, x, y, bw, bh])\n",
    "\n",
    "    else:\n",
    "        # Уменьшение -> Паддинг (по центру)\n",
    "        pad_x = (w - new_w) // 2\n",
    "        pad_y = (h - new_h) // 2\n",
    "        final_img = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        final_img[pad_y:pad_y + new_h, pad_x:pad_x + new_w] = resized_img\n",
    "\n",
    "        # Корректируем YOLO боксы (центр + размер)\n",
    "        new_bboxes = []\n",
    "        for class_id, x, y, bw, bh in bboxes:\n",
    "            x = ((x * new_w) + pad_x) / w\n",
    "            y = ((y * new_h) + pad_y) / h\n",
    "            bw = (bw * new_w) / w\n",
    "            bh = (bh * new_h) / h\n",
    "            new_bboxes.append([class_id, x, y, bw, bh])\n",
    "\n",
    "    return final_img, new_bboxes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Загружаем все изображения\n",
    "image_paths = glob(os.path.join(input_images_dir, \"*.jpg\"))\n",
    "\n",
    "for image_path in image_paths:\n",
    "    # Загружаем изображение\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Загружаем аннотации (YOLO format)\n",
    "    label_path = os.path.join(input_labels_dir, os.path.basename(image_path).replace(\".jpg\", \".txt\"))\n",
    "    \n",
    "    if not os.path.exists(label_path):\n",
    "        continue  # Пропускаем, если нет аннотации\n",
    "    \n",
    "    with open(label_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    bboxes = []\n",
    "    for line in lines:\n",
    "        values = line.split()\n",
    "        class_id = int(values[0])\n",
    "        x, y, w, h = map(float, values[1:])\n",
    "        bboxes.append([class_id, x, y, w, h])\n",
    "    \n",
    "    #  Применяем аугментации\n",
    "    augmented_images = []\n",
    "    augmented_bboxes = []\n",
    "\n",
    "    # 0 Горизонтальный флип\n",
    "    flipped_img, flipped_boxes = flip_image(img, bboxes, flip_code=1)\n",
    "    augmented_images.append(flipped_img)\n",
    "    augmented_bboxes.append(flipped_boxes)\n",
    "\n",
    "    # 1 Вертикальный флип\n",
    "    flipped_img, flipped_boxes = flip_image(img, bboxes, flip_code=0)\n",
    "    augmented_images.append(flipped_img)\n",
    "    augmented_bboxes.append(flipped_boxes)\n",
    "\n",
    "    # 2 Яркость\n",
    "    bright_img = adjust_brightness(img, factor=1.4)\n",
    "    augmented_images.append(bright_img)\n",
    "    augmented_bboxes.append(bboxes)\n",
    "\n",
    "    # 3 Яркость\n",
    "    bright_img = adjust_brightness(img, factor=0.5)\n",
    "    augmented_images.append(bright_img)\n",
    "    augmented_bboxes.append(bboxes)\n",
    "\n",
    "    # 4 Шум\n",
    "    noisy_img = add_noise(img)\n",
    "    augmented_images.append(noisy_img)\n",
    "    augmented_bboxes.append(bboxes)\n",
    "\n",
    "\n",
    "    # 5 Масштабирование\n",
    "    scaled_img, scaled_boxes = scale_image(img, bboxes, scale_factor=1.4)\n",
    "    augmented_images.append(scaled_img)\n",
    "    augmented_bboxes.append(scaled_boxes)\n",
    "\n",
    "\n",
    "    # 6  Масштабирование\n",
    "    scaled_img, scaled_boxes = scale_image(img, bboxes, scale_factor=0.8)\n",
    "    augmented_images.append(scaled_img)\n",
    "    augmented_bboxes.append(scaled_boxes)\n",
    "\n",
    "\n",
    "\n",
    "    # Сохраняем аугментированные изображения и аннотации\n",
    "    for i, (aug_img, aug_boxes) in enumerate(zip(augmented_images, augmented_bboxes)):\n",
    "        aug_boxes = clip_bbox(aug_boxes) \n",
    "        output_image_path = os.path.join(output_images_dir, f\"{os.path.basename(image_path).replace('.jpg', '')}_aug{i}.jpg\")\n",
    "        cv2.imwrite(output_image_path, cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "        output_label_path = os.path.join(output_labels_dir, f\"{os.path.basename(label_path).replace('.txt', '')}_aug{i}.txt\")\n",
    "        with open(output_label_path, \"w\") as f:\n",
    "            for bbox in aug_boxes:\n",
    "                f.write(f\"{bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]} {bbox[4]}\\n\")\n",
    "\n",
    "print(\"Аугментированный датасет сохранён!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-25.02",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
